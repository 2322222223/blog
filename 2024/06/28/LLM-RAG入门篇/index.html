<!DOCTYPE html>
<html lang="zh-CN">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="x5-fullscreen" content="true">
<meta name="full-screen" content="yes">
<meta name="theme-color" content="#317EFB" />
<meta content="width=device-width, initial-scale=1.0, maximum-scale=5.0, user-scalable=0" name="viewport">
<meta name="description" content="LLM-RAG篇一、LLMs 已经具备了较强能力了，为什么还需要 RAG(检索增强生成)?尽管 LLM 已展现出显著的能力，但以下几个挑战依然值得关注：  幻觉问题：LLM 采用基于统计的概率方法逐词生成文本，这一机制内在地导致其可能出现看似逻辑严谨实则缺乏事实依据的输出，即所谓的“郑重其事的虚构陈述”； 时效性问题：随着 LLM 规模扩大，训练成本与周期相应增加。鉴于此，包含最新信息的数据难以融">
<meta property="og:type" content="article">
<meta property="og:title" content="LLM-RAG篇">
<meta property="og:url" content="https://2322222223.github.io/blog/2024/06/28/LLM-RAG%E5%85%A5%E9%97%A8%E7%AF%87/index.html">
<meta property="og:site_name" content="Rlz Blog">
<meta property="og:description" content="LLM-RAG篇一、LLMs 已经具备了较强能力了，为什么还需要 RAG(检索增强生成)?尽管 LLM 已展现出显著的能力，但以下几个挑战依然值得关注：  幻觉问题：LLM 采用基于统计的概率方法逐词生成文本，这一机制内在地导致其可能出现看似逻辑严谨实则缺乏事实依据的输出，即所谓的“郑重其事的虚构陈述”； 时效性问题：随着 LLM 规模扩大，训练成本与周期相应增加。鉴于此，包含最新信息的数据难以融">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://2322222223.github.io/blog/img/404.jpg">
<meta property="og:image" content="https://2322222223.github.io/blog/img/404.jpg">
<meta property="article:published_time" content="2024-06-28T09:03:12.000Z">
<meta property="article:modified_time" content="2024-07-01T13:49:47.029Z">
<meta property="article:author" content="R.linzhou">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="ARG">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://2322222223.github.io/blog/img/404.jpg">


<title >LLM-RAG篇</title>

<!-- Favicon -->

    <link href='/blog/img/logo.svg?v=2.2.2' rel='icon' type='image/png' sizes='16x16' ></link>


    <link href='/blog/img/logo.svg?v=2.2.2' rel='icon' type='image/png' sizes='32x32' ></link>




<!-- Plugin -->




    
<link rel="stylesheet" href="/blog/css/plugins/bootstrap.row.css">

    
<link rel="stylesheet" href="https://unpkg.com/@fancyapps/ui@4.0/dist/fancybox.css">

    
    




<!-- Icon -->

    
<link rel="stylesheet" href="/blog/css/plugins/font-awesome.min.css">




<!-- Variable -->
<script>window.ASYNC_CONFIG = {"hostname":"2322222223.github.io","author":"R.linzhou","root":"/blog/","typed_text":["Mobile development"],"theme_version":"2.2.2","theme":{"switch":true,"default":"style-light"},"favicon":{"logo":"/img/logo.svg","icon16":"/img/logo.svg","icon32":"/img/logo.svg","apple_touch_icon":null,"webmanifest":null,"visibilitychange":false,"hidden":"/ogo.svg","show_text":"R.linzhou Blog","hide_text":"R.linzhou Blog"},"i18n":{"placeholder":"搜索文章...","empty":"找不到您查询的内容: ${query}","hits":"找到 ${hits} 条结果","hits_time":"找到 ${hits} 条结果（用时 ${time} 毫秒）","author":"本文作者：","copyright_link":"本文链接：","copyright_license_title":"版权声明：","copyright_license_content":"本博客所有文章除特别声明外，均默认采用 undefined 许可协议。","copy_success":"复制成功","copy_failure":"复制失败","open_read_mode":"进入阅读模式","exit_read_mode":"退出阅读模式","notice_outdate_message":"距离上次更新已经 undefined 天了, 文章内容可能已经过时。","sticky":"置顶","just":"刚刚","min":"分钟前","hour":"小时前","day":"天前","month":"个月前"},"swup":false,"plugin":{"flickr_justified_gallery":"https://unpkg.com/flickr-justified-gallery@latest/dist/fjGallery.min.js"},"icons":{"sun":"far fa-sun","moon":"far fa-moon","play":"fas fa-play","email":"far fa-envelope","next":"fas fa-arrow-right","calendar":"far fa-calendar-alt","clock":"far fa-clock","user":"far fa-user","back_top":"fas fa-arrow-up","close":"fas fa-times","search":"fas fa-search","reward":"fas fa-hand-holding-usd","user_tag":"fas fa-user-alt","toc_tag":"fas fa-th-list","read":"fas fa-book-reader","arrows":"fas fa-arrows-alt-h","double_arrows":"fas fa-angle-double-down","copy":"fas fa-copy"},"icontype":"font","highlight":{"plugin":"highlighjs","theme":true,"copy":true,"lang":false,"title":"default","height_limit":200},"toc":{"post_title":true},"live_time":{"start_time":"","prefix":"博客已萌萌哒运行 undefined 天"},"danmu":{"enable":false,"el":".trm-banner"},"creative_commons":{"license":"by-nc-sa","language":"deed.zh"}};</script>
<script id="async-page-config">window.PAGE_CONFIG = {"isPost":true,"isHome":false,"postUpdate":"2024-07-01 21:49:47"};</script>

<!-- Theme mode css -->
<link data-swup-theme rel="stylesheet" href="/blog/css/index.css?v=2.2.2" id="trm-switch-style">
<script>
    let defaultMode = ASYNC_CONFIG.theme.default !=='auto' ?  ASYNC_CONFIG.theme.default : (window.matchMedia("(prefers-color-scheme: light)").matches ? 'style-light' : 'style-dark')
    let catchMode = localStorage.getItem('theme-mode') || defaultMode;
    let type = catchMode === 'style-dark' ? 'add' : 'remove';
    document.documentElement.classList[type]('dark')
</script>

<!-- CDN -->


    
    



<!-- Site Analytics -->

 
<meta name="generator" content="Hexo 7.2.0"></head>

<body>

  <!-- app wrapper -->
  <div class="trm-app-frame">

    <!-- page preloader -->
    <div class="trm-preloader">
    <div class="trm-holder">
        <div class="preloader">
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
        </div>
    </div>
</div>
    <!-- page preloader end -->

    <!-- change mode preloader -->
    <div class="trm-mode-swich-animation-frame">
    <div class="trm-mode-swich-animation">
        <i class="i-sun"><i class="iconfont far fa-sun"></i></i>
        <div class="trm-horizon"></div>
        <i class="i-moon"><i class="iconfont far fa-moon"></i></i>
    </div>
</div>
    <!-- change mode preloader end -->

      <!-- scroll container -->
      <div id="trm-dynamic-content" class="trm-swup-animation">
        <div id="trm-scroll-container" class="trm-scroll-container" style="opacity: 0">
            <!-- top bar -->
            <header class="trm-top-bar">
	<div class="container">
		<div class="trm-left-side">
			<!-- logo -->
<a href="/blog/" class="trm-logo-frame trm-anima-link">
    
        <img alt="logo" src="/blog/img/logo.svg">
    
    
        <div class="trm-logo-text">
            Blog<span></span>
        </div>
    
</a>
<!-- logo end -->
		</div>
		<div class="trm-right-side">
			<!-- menu -->
<div class="trm-menu">
    <nav>
        <ul>
            
            <li class="menu-item-has-children ">
                <a  href="/blog/" target="">
                    home
                </a>
                
            </li>
            
            <li class="menu-item-has-children ">
                <a data-no-swup href="/blog/archives/" target="">
                    archives
                </a>
                
            </li>
            
        </ul>
    </nav>
</div>
<!-- menu end -->
			
    <!-- mode switcher place -->
    <div class="trm-mode-switcher-place">
        <div class="trm-mode-switcher">
            <i class="iconfont far fa-sun"></i>
            <input class="tgl tgl-light" id="trm-swich" type="checkbox">
            <label class="trm-swich" for="trm-swich"></label>
            <i class="iconfont far fa-moon"></i>
        </div>
    </div>
    <!-- mode switcher place end -->

			
		</div>
		<div class="trm-menu-btn">
			<span></span>
		</div>
	</div>
</header>
            <!-- top bar end -->

            <!-- body -->
            
<div class="trm-content-start">
    <!-- banner -->
    <div class="trm-banner">
    
    <!-- banner cover -->
    <img style="object-position:top;object-fit:cover;" alt="banner" class="trm-banner-cover" src="/blog/img/banner.png">
    <!-- banner cover end -->
    

    <!-- banner content -->
    <div class="trm-banner-content trm-overlay">
        <div class="container">
            <div class="row">
                
                <div class="col-lg-4"></div>
                
                <div class="col-lg-8">

                    <!-- banner title -->
                    <div class="trm-banner-text ">
                        <div class="trm-label trm-mb-20">
                            NEWS LETTER
                        </div>
                        <h1 class="trm-mb-30 trm-hsmb-font">
                            LLM-RAG篇
                        </h1>

                        
                            <ul class="trm-breadcrumbs trm-label">
                                <li>
                                    <a href="/blog/" class="trm-anima-link">Home</a>
                                </li>
                                <li>
                                    <span>
                                        2024
                                    </span>
                                </li>
                            </ul>
                        
                    </div>
                    <!-- banner title end -->

                    <!-- scroll hint -->
                    <span id="scroll-triger" class="trm-scroll-hint-frame">
                        <div class="trm-scroll-hint"></div>
                        <span class="trm-label">Scroll down</span>
                    </span>
                    <!-- scroll hint end -->

                </div>
            </div>
        </div>
    </div>
    <!-- banner content end -->
</div>
    <!-- banner end -->
    <div class="container">
        <div class="row">
            
                <div class="trm-page-sidebar col-lg-4 hidden-sm">
                    <!-- main card -->
                    <div class="trm-main-card-frame trm-sidebar">
    <div class="trm-main-card"> 
        <!-- card header -->
<div class="trm-mc-header">
    <div class="trm-avatar-frame trm-mb-20">
        <img alt="Avatar" class="trm-avatar" src="/blog/img/avatar.png">
    </div>
    <h5 class="trm-name trm-mb-15">
        R.linzhou
    </h5>
    
        <div class="trm-label">
            I&#39;m
            <span class="trm-typed-text">
                <!-- Words for theme.user.typedText -->
            </span>
        </div>
    
</div>
<!-- card header end -->
        <!-- sidebar social -->

<div class="trm-divider trm-mb-40 trm-mt-40"></div>
<div class="trm-social">
    
        <a href="https://github.com/2322222223" title="Github" rel="nofollow" target="_blank">
            <i class="iconfont fab fa-github"></i>
        </a>
    
        <a href="http://2322222223.com" title="Resume" rel="nofollow" target="_blank">
            <i class="iconfont far fa-smile"></i>
        </a>
    
</div>

<!-- sidebar social end -->
        <!-- info -->
<div class="trm-divider trm-mb-40 trm-mt-40"></div>
<ul class="trm-table trm-mb-20">
    
        <li>
            <div class="trm-label">
                地址:
            </div>
            <div class="trm-label trm-label-light">
                Beijing
            </div>
        </li>
    
        <li>
            <div class="trm-label">
                年龄:
            </div>
            <div class="trm-label trm-label-light">
                32
            </div>
        </li>
    
        <li>
            <div class="trm-label">
                邮箱:
            </div>
            <div class="trm-label trm-label-light">
                g2322222223@gmail.com
            </div>
        </li>
    
</ul>
<!-- info end -->

        
    <div class="trm-divider trm-mb-40 trm-mt-40"></div>
    <!-- action button -->
    <div class="text-center">
        <a href="mailto:g2322222223@gmail.com" class="trm-btn">
            联系我
            <i class="iconfont far fa-envelope"></i>
        </a>
    </div>
    <!-- action button end -->

    </div>
</div>
                    <!-- main card end -->
                </div>
            
            <div class="trm-page-content col-lg-8">
                <div id="trm-content" class="trm-content">
                    <div class="trm-post-info row hidden-sm">
    <div class="col-sm-4">
        <div class="trm-card trm-label trm-label-light text-center">
            <i class="iconfont far fa-calendar-alt trm-icon"></i><br>
            06/28
        </div>
    </div>
    <div class="col-sm-4">
        <div class="trm-card trm-label trm-label-light text-center">
            <i class="iconfont far fa-clock trm-icon"></i><br>
            17:03
        </div>
    </div>
    <div class="col-sm-4">
        <div id="post-author" class="trm-card trm-label trm-label-light text-center">
            <i class="iconfont far fa-user trm-icon"></i><br>
            R.linzhou
        </div>
    </div>
</div>
<div class="trm-card ">
    <article id="article-container" class="trm-publication">
    <h2 id="LLM-RAG篇"><a href="#LLM-RAG篇" class="headerlink" title="LLM-RAG篇"></a>LLM-RAG篇</h2><h2 id="一、LLMs-已经具备了较强能力了，为什么还需要-RAG-检索增强生成"><a href="#一、LLMs-已经具备了较强能力了，为什么还需要-RAG-检索增强生成" class="headerlink" title="一、LLMs 已经具备了较强能力了，为什么还需要 RAG(检索增强生成)?"></a><strong>一、LLMs 已经具备了较强能力了，为什么还需要 RAG(检索增强生成)?</strong></h2><p>尽管 LLM 已展现出显著的能力，但以下几个挑战依然值得关注：</p>
<ol>
<li><strong>幻觉问题</strong>：LLM 采用基于统计的概率方法逐词生成文本，这一机制内在地导致其可能出现看似逻辑严谨实则缺乏事实依据的输出，即所谓的“郑重其事的虚构陈述”；</li>
<li><strong>时效性问题</strong>：随着 LLM 规模扩大，训练成本与周期相应增加。鉴于此，包含最新信息的数据难以融入模型训练过程，导致 LLM 在应对诸如“请推荐当前热门影片”等时间敏感性问题时力有未逮；</li>
<li><strong>数据安全问题</strong>：通用的 LLM 没有企业内部数据和用户数据，那么企业想要在保证安全的前提下使用 LLM，最好的方式就是把数据全部放在本地，企业数据的业务计算全部在本地完成。而在线的大模型仅仅完成一个归纳的功能；</li>
</ol>
<h2 id="二、介绍一下-RAG"><a href="#二、介绍一下-RAG" class="headerlink" title="二、介绍一下 RAG"></a><strong>二、介绍一下 RAG</strong></h2><p>RAG（Retrieval Augmented Generation, 检索增强生成）是一种技术框架，其核心在于当 LLM 面对解答问题或创作文本任务时，首先会在大规模文档库中搜索并筛选出与任务紧密相关的素材，继而依据这些素材精准指导后续的回答生成或文本构造过程，旨在通过此种方式提升模型输出的准确性和可靠性。</p>
<h2 id="三、RAG-主要包含哪些模块"><a href="#三、RAG-主要包含哪些模块" class="headerlink" title="三、RAG 主要包含哪些模块?"></a><strong>三、RAG 主要包含哪些模块?</strong></h2><ol>
<li>模块一：版面分析</li>
<li>本地知识文件读取（pdf、txt、html、doc、excel、png、jpg、语音等）</li>
<li>知识文件复原</li>
<li>模块二：知识库构建</li>
<li>知识文本分割，并构建Doc文本</li>
<li>Doc文本 embedding</li>
<li>Doc文本 构建索引</li>
<li>模块三：大模型微调</li>
<li>模块四：基于RAG的知识问答</li>
<li>用户query embedding</li>
<li>query 召回</li>
<li>query 排序</li>
<li>将 Top K 个相关的 Doc 进行拼接，构建 context</li>
<li>基于 query 和 context 构建 Prompt</li>
<li>将 prompt 喂给大模型生成答案</li>
</ol>
<h2 id="四、RAG-相较于直接使用-LLMs进行问答-有哪些优点"><a href="#四、RAG-相较于直接使用-LLMs进行问答-有哪些优点" class="headerlink" title="四、RAG 相较于直接使用 LLMs进行问答 有哪些优点?"></a><strong>四、RAG 相较于直接使用 LLMs进行问答 有哪些优点?</strong></h2><p>RAG（检索增强生成）方法赋予了开发者无需为每个特定任务重新训练大型模型的能力，仅需连接外部知识库，即可为模型注入额外的信息资源，从而显著提升其回答的精确度。这一方法尤其适用于那些高度依赖专业知识的任务。</p>
<p>以下是 RAG 模型的主要优势：</p>
<ol>
<li><strong>可扩展性</strong>：减小模型规模及训练开销，同时简化知识库的扩容更新过程。</li>
<li><strong>准确性</strong>：通过引用信息源，用户能够核查答案的可信度，进而增强对模型输出结果的信任感。</li>
<li><strong>可控性</strong>：支持知识内容的灵活更新与个性化配置。</li>
<li><strong>可解释性</strong>：展示模型预测所依赖的检索条目，增进理解与透明度。</li>
<li><strong>多功能性</strong>：RAG 能够适应多种应用场景的微调与定制，涵盖问答、文本摘要、对话系统等领域。</li>
<li><strong>时效性</strong>：运用检索技术捕捉最新信息动态，确保回答既即时又准确，相比仅依赖固有训练数据的语言模型具有明显优势。</li>
<li><strong>领域定制性</strong>：通过对接特定行业或领域的文本数据集，RAG 能够提供针对性的专业知识支持。</li>
<li><strong>安全性</strong>：通过在数据库层面实施角色划分与安全管控，RAG 有效强化了对数据使用的管理，相较于微调模型在数据权限管理上的潜在模糊性，展现出更高的安全性。</li>
</ol>
<h2 id="五、对比一下-RAG-和-SFT，说一下两者有哪些区别？"><a href="#五、对比一下-RAG-和-SFT，说一下两者有哪些区别？" class="headerlink" title="五、对比一下 RAG 和 SFT，说一下两者有哪些区别？"></a><strong>五、对比一下 RAG 和 SFT，说一下两者有哪些区别？</strong></h2><p>实际上，对于 LLM 存在的上述问题，SFT 是一个最常见最基本的解决办法，也是 LLM 实现应用的基础步骤。那么有必要在多个维度上比较一下两种方法：</p>
<p><img src="/blog/image.png" alt="img"  data-tag='post-image' loading="lazy" onerror='this.onerror=null;this.src="/blog/img/404.jpg"'></p>
<p>当然这两种方法并非非此即彼的，合理且必要的方式是结合业务需要与两种方法的优点，合理使用两种方法。</p>
<p><img src="/blog/image1.png" alt="img"  data-tag='post-image' loading="lazy" onerror='this.onerror=null;this.src="/blog/img/404.jpg"'></p>
<h2 id="SimpleRAG-实战篇"><a href="#SimpleRAG-实战篇" class="headerlink" title="SimpleRAG 实战篇"></a><strong>SimpleRAG 实战篇</strong></h2><h2 id="模块一：版面分析"><a href="#模块一：版面分析" class="headerlink" title="模块一：版面分析"></a><strong>模块一：版面分析</strong></h2><h3 id="为什么-需要-版面分析？"><a href="#为什么-需要-版面分析？" class="headerlink" title="为什么 需要 版面分析？"></a><strong>为什么 需要 版面分析？</strong></h3><p>尽管RAG（检索增强生成）技术的核心价值在于其结合检索与生成手段以提升文本内容的精确度与连贯性，然而在一些具体应用领域，如文档解析、智能化写作及对话系统构建中，特别是在面对结构化或半结构化信息的处理需求时，其功能边界可能拓展至版面分析。这是由于此类信息往往嵌于特定的布局结构中，需要对页面元素及其相互关系进行深入理解。</p>
<p>此外，当RAG模型面对包含丰富多媒体或多模态成分的数据源，诸如网页、PDF文件、富文本记录、Word文档、图像资料、语音片段、表格数据等复杂内容时，为了能高效地摄取并利用这些非文本信息，具备基本的版面分析能力变得至关重要。这种能力有助于模型精准解析各类信息单元，并成功将它们融合成有意义的整体解读。</p>
<h3 id="step-1：本地知识文件获取"><a href="#step-1：本地知识文件获取" class="headerlink" title="step 1：本地知识文件获取"></a><strong>step 1：本地知识文件获取</strong></h3><h4 id="q1：如何进行-本地知识文件获取？"><a href="#q1：如何进行-本地知识文件获取？" class="headerlink" title="q1：如何进行 本地知识文件获取？"></a><strong>q1：如何进行 本地知识文件获取？</strong></h4><p>本地知识文件获取涉及从多种数据源（如.txt、.pdf、.html、.doc、.xlsx、.png、.jpg、音频文件等）提取信息的过程。针对不同类型的文件，需要采取特定的访问与解析策略来有效获取其中蕴含的知识。下面我们将介绍对于不同数据源数据的获取方式和难点。</p>
<h4 id="q2：如何获取-富文本txt-中内容？"><a href="#q2：如何获取-富文本txt-中内容？" class="headerlink" title="q2：如何获取 富文本txt 中内容？"></a>q2：如何获取 富文本txt 中内容？</h4><ol>
<li>介绍：富文本 主要存储于 txt 文件中，因为排版比较整洁，所以获取方式比较简单</li>
</ol>
<h4 id="q3：如何获取-PDF文档-中内容？"><a href="#q3：如何获取-PDF文档-中内容？" class="headerlink" title="q3：如何获取 PDF文档 中内容？"></a><strong>q3：如何获取 PDF文档 中内容？</strong></h4><ol>
<li>介绍：PDF文档中数据比较复杂，包含文本、图片、表格等不同样式的数据，所以解析过程中会比较复杂</li>
</ol>
<h4 id="q4：如何获取-HTML文档-中内容？"><a href="#q4：如何获取-HTML文档-中内容？" class="headerlink" title="q4：如何获取 HTML文档 中内容？"></a><strong>q4：如何获取 HTML文档 中内容？</strong></h4><ol>
<li>介绍：PDF文档中数据比较复杂，包含文本、图片、表格等不同样式的数据，所以解析过程中会比较复杂</li>
</ol>
<h4 id="q5：如何获取-Doc文档-中内容？"><a href="#q5：如何获取-Doc文档-中内容？" class="headerlink" title="q5：如何获取 Doc文档 中内容？"></a><strong>q5：如何获取 Doc文档 中内容？</strong></h4><ol>
<li>介绍：Doc文档中数据比较复杂，包含文本、图片、表格等不同样式的数据，所以解析过程中会比较复杂</li>
</ol>
<h4 id="q6：如何使用-OCR-获取图片内容？"><a href="#q6：如何使用-OCR-获取图片内容？" class="headerlink" title="q6：如何使用 OCR 获取图片内容？"></a><strong>q6：如何使用 OCR 获取图片内容？</strong></h4><ol>
<li>介绍：光学字符识别（Optical Character Recognition, OCR）是指对文本资料的图像文件进行分析识别处理，获取文字及版面信息的过程。亦即将图像中的文字进行识别，并以文本的形式返回。</li>
<li>思路：</li>
<li>文字检测：解决的问题是哪里有文字，文字的范围有多少；</li>
<li>文字识别：对定位好的文字区域进行识别，主要解决的问题是每个文字是什么，将图像中的文字区域进转化为字符信息。</li>
</ol>
<h4 id="q7：如何使用-ASR-获取语音内容？"><a href="#q7：如何使用-ASR-获取语音内容？" class="headerlink" title="q7：如何使用 ASR 获取语音内容？"></a><strong>q7：如何使用 ASR 获取语音内容？</strong></h4><ol>
<li>别称：自动语音识别AutomaTlc Speech RecogniTlon，(ASR)</li>
<li>介绍：将一段语音信号转换成相对应的文本信息，好比”机器的听觉系统”，它让机器通过识别和理解，把语音信号转变为相应的文本或命令。</li>
<li>目标：将人类的语音中的词汇内容转换为计算机可读的输入（eg:按键、二进制编码或者字符序列）</li>
<li>思路：</li>
<li>声学信号预处理：为了更有效地提取特征往往还需要对所采集到的声音信号进行滤波、分帧等预处理工作，把要分析的信号从原始信号中提取出来；</li>
<li>特征提取：将声音信号从时域转换到频域，为声学模型提供合适的特征向量;</li>
<li>声学模型：根据声学特性计算每一个特征向量在声学特征上的得分;</li>
<li>语言模型：根据语言学相关的理论，计算该声音信号对应可能词组序列的概率;</li>
<li>字典与解码：根据已有的字典，对词组序列进行解码，得到最后可能的文本表示</li>
</ol>
<h3 id="step-2：知识文件复原"><a href="#step-2：知识文件复原" class="headerlink" title="step 2：知识文件复原"></a><strong>step 2：知识文件复原</strong></h3><h4 id="q1：为什么需要进行-知识文件复原？"><a href="#q1：为什么需要进行-知识文件复原？" class="headerlink" title="q1：为什么需要进行 知识文件复原？"></a><strong>q1：为什么需要进行 知识文件复原？</strong></h4><p>本地知识文件获取包含对多源化数据（txt、pdf、html、doc、excel、png、jpg、语音等）进行读取之后，容易将一个多行段落分割成多个段落，从而导致段落遇到被分割，所以需要根据内容逻辑重新组织段落。</p>
<h4 id="q2：如何对-知识文件进行复原？"><a href="#q2：如何对-知识文件进行复原？" class="headerlink" title="q2：如何对 知识文件进行复原？"></a><strong>q2：如何对 知识文件进行复原？</strong></h4><ol>
<li>方法一：基于规则的知识文件复原</li>
<li>思路：根据识别段落的左右边距和末尾的标点符号进行合并</li>
<li>如何判断该段落是否为原始段落末尾？</li>
<li>如果最后一个字符离有边界距离较远，那么该段落为句子的末尾</li>
<li>如果最后一个字符为 句号 或者其他终止符，那么该段落为句子的末尾</li>
<li>方法二：基于 Bert NSP 进行上下句拼接</li>
<li>思路：<strong>语义切分方法2</strong>：除了discourse parsing的工具外，还可以写一个简单算法<strong>利用BERT等模型来实现语义分割</strong>。BERT等模型在预训练的时候采用了NSP（next sentence prediction）的训练任务，因此BERT完全可以判断两个句子（段落）是否具有语义衔接关系。这里我们可以设置相似度阈值t，从前往后依次判断相邻两个段落的相似度分数是否大于t，如果大于则合并，否则断开。当然算法为了效率，可以采用二分法并行判定，模型也不用很大，笔者用BERT-base-Chinese在中文场景中就取得了不错的效果。</li>
<li>代码逻辑：</li>
</ol>
<p>基于 Bert NSP 进行上下句预测代码</p>
<p> def is_nextsent(sent, next_sent):</p>
<p>​        encoding &#x3D; tokenizer(sent, next_sent, return_tensors&#x3D;”pt”,truncation&#x3D;True, padding&#x3D;False)</p>
<p>​        with torch.no_grad():</p>
<p>​            outputs &#x3D; model(**encoding, labels&#x3D;torch.LongTensor([1]))</p>
<p>​            logits &#x3D; outputs.logits</p>
<p>​            probs &#x3D; torch.softmax(logits&#x2F;TEMPERATURE, dim&#x3D;1)</p>
<p>​            next_sentence_prob &#x3D; probs[:, 0].item()</p>
<p>​        if next_sentence_prob &lt;&#x3D; MERGE_RATIO:</p>
<p>​            return False</p>
<p>​        else:</p>
<p>​            return True</p>
<h3 id="step-4：Homework"><a href="#step-4：Homework" class="headerlink" title="step 4：Homework"></a><strong>step 4：Homework</strong></h3><ol>
<li>任务描述：使用上述方法对 【<a target="_blank" rel="noopener" href="https://tianchi.aliyun.com/specials/promotion/SMP2023ChatGLMChallenge">SMP 2023 ChatGLM金融大模型挑战赛</a>】的 【<a target="_blank" rel="noopener" href="https://modelscope.cn/datasets/modelscope/chatglm_llm_fintech_raw_dataset/summary?spm=a2c22.12281978.0.0.13472420ZI1gfg">ChatGLM评估挑战赛-金融赛道数据集</a>】进行版面分析</li>
<li>任务效果：分析各种方法效果和性能</li>
</ol>
<h2 id="模块二：知识库构建"><a href="#模块二：知识库构建" class="headerlink" title="模块二：知识库构建"></a><strong>模块二：知识库构建</strong></h2><h3 id="为什么-需要-知识库构建？"><a href="#为什么-需要-知识库构建？" class="headerlink" title="为什么 需要 知识库构建？"></a><strong>为什么 需要 知识库构建？</strong></h3><p>在RAG（Retrieval-Augmented Generation）中构建知识库是至关重要的，原因包括但不限于以下几点：</p>
<ol>
<li><strong>扩展模型能力</strong>：大规模语言模型如GPT系列虽然具有强大的语言生成和理解能力，但受限于训练数据集的覆盖范围，它们可能无法准确回答一些基于特定事实或详细背景信息的问题。通过构建知识库，RAG可以补充模型自身的知识局限性，允许模型检索到最新、最准确的信息来生成答案。</li>
<li><strong>实时更新信息</strong>：知识库可以实时更新和扩充，确保模型能够获取最新的知识内容，这对于处理时效性强的信息尤为关键，比如新闻事件、科技进展等。</li>
<li><strong>提高准确性</strong>：RAG结合了检索与生成两个过程，在生成回答前先检索相关文档，从而提高了回答问题时的准确性。这样，模型生成的答案不仅基于其内部参数化的知识，还基于外部可靠来源的知识库。</li>
<li><strong>减少过拟合与hallucination（幻觉生成）</strong>：大模型有时会因为过度依赖内在模式而出现hallucination现象，即生成看似合理实则无依据的答案。通过引用知识库中的确切证据，RAG可以降低此类错误产生的可能性。</li>
<li><strong>增强可解释性</strong>：RAG不仅能提供答案，还能指出答案的来源，增强了模型生成结果的透明度和可信度。</li>
<li><strong>支持个性化及私有化需求</strong>： 对于企业或个人用户，可以通过构建专属知识库满足特定领域或私人定制的需求，使得大模型能更好地服务于特定场景和业务。</li>
</ol>
<p>综上所述，构建知识库对于RAG模型来说，是实现高效准确地检索并生成答案的核心机制之一，它极大地提升了模型在实际应用中的性能和可靠性。</p>
<h3 id="step-1：知识文本分块"><a href="#step-1：知识文本分块" class="headerlink" title="step 1：知识文本分块"></a><strong>step 1：知识文本分块</strong></h3><ol>
<li>为什么需要对文本分块？</li>
<li><strong>信息丢失的风险</strong>：试图一次性提取整个文档的嵌入向量，虽然可以捕捉到整体的上下文，但也可能会忽略掉许多针对特定主题的重要信息，这可能会导致生成的信息不够精确或者有所缺失。</li>
<li><strong>分块大小的限制</strong>：在使用如OpenAI这样的模型时，分块大小是一个关键的限制因素。例如，GPT-4模型有一个32K的窗口大小限制。尽管这个限制在大多数情况下不是问题，但从一开始就考虑到分块大小是很重要的。</li>
<li>主要考虑两个因素：</li>
<li>embedding模型的Tokens限制情况；</li>
<li>语义完整性对整体的检索效果的影响；</li>
</ol>
<h3 id="step-2：Docs-向量化（embdeeing）"><a href="#step-2：Docs-向量化（embdeeing）" class="headerlink" title="step 2：Docs 向量化（embdeeing）"></a><strong>step 2：Docs 向量化（embdeeing）</strong></h3><h4 id="q1：什么是Docs-向量化（embdeeing）？"><a href="#q1：什么是Docs-向量化（embdeeing）？" class="headerlink" title="q1：什么是Docs 向量化（embdeeing）？"></a><strong>q1：什么是Docs 向量化（embdeeing）？</strong></h4><p>Embedding 也是文本语义含义的信息密集表示，每个嵌入都是一个浮点数向量，使得向量空间中两个嵌入之间的距离与原始格式中两个输入之间的语义相似性相关联。</p>
<p>例如，如果两个文本相似，则它们的向量表示也应该相似，这一组向量空间内的数组表示描述了文本之间的细微特征差异。</p>
<p>简单来说，Embedding 帮助计算机来理解如人类信息所代表的“含义”，Embedding 可以用来获取文本、图像、视频、或其他信息的特征“相关性”，这种相关性在应用层面常用于搜索、推荐、分类、聚类。</p>
<h4 id="q2：Embedding-是如何工作的？"><a href="#q2：Embedding-是如何工作的？" class="headerlink" title="q2：Embedding 是如何工作的？"></a><strong>q2：Embedding 是如何工作的？</strong></h4><p>举例来讲，这里有三句话：</p>
<ol>
<li>“The cat chases the mouse” “猫追逐老鼠”</li>
<li>“The kitten hunts rodents” 小猫捕猎老鼠。</li>
<li>“I like ham sandwiches” 我喜欢火腿三明治。</li>
</ol>
<p>如果是人类来将这三个句子来分类，句子 1 和句子 2 几乎是同样的含义，而句子 3 却完全不同。但我们看到在英文原文句子中，句子 1 和句子 2 只有“The”是相同的，没有其他相同词汇。计算机该如何理解前两个句子的相关性？</p>
<p>Embedding 将离散信息（单词和符号）压缩为分布式连续值数据（向量）。如果我们将之前的短语绘制在图表上，它可能看起来像这样：</p>
<p>在文本被 Embedding 压缩到计算机可以理解的多维向量化空间之后，由于句子 1 和 2 的含义相似，它们会被绘制在彼此附近。句子 3 却距离较远，因为它与它们没有关联。如果我们有第四个短语 “Sally 吃了瑞士奶酪”，它可能存在于句子 3（奶酪可以放在三明治上）和句子 1（老鼠喜欢瑞士奶酪）之间的某个地方。</p>
<h4 id="q3：Embedding-的语义检索方式对比关键词检索的优势？"><a href="#q3：Embedding-的语义检索方式对比关键词检索的优势？" class="headerlink" title="q3：Embedding 的语义检索方式对比关键词检索的优势？"></a><strong>q3：Embedding 的语义检索方式对比关键词检索的优势？</strong></h4><ol>
<li><strong>语义理解</strong>： 基于 Embedding 的检索方法通过词向量来表示文本，这使得模型能够捕捉到词汇之间的语义联关系，相比之下，基于关键词的检索往往关注字面匹配，可能忽略了词语之间的语义联系。</li>
<li><strong>容错性</strong>： 由于基于 Embedding 的方法能够理解词汇之间的关系，所以在处理拼写错误、同义词、近义词等情况时更具优势。而基于关键词的检索方法对这些情况的处理相对较弱。</li>
<li><strong>多语言支持</strong>： 许多 Embedding 方法可以支持多种语言，有助于实现跨语言的文本检索。比如你可以用中文输入来查询英文文本内容，而基于关键词的检索方法很难做到这一点。</li>
<li><strong>语境理解</strong>： 基于 Embedding 的方法在处理一词多义的情况时更具优势，因为它能够根据上下文为词语赋予不同的向量表示。而基于关键词的检索方法可能无法很好地区分同一个词在不同语境下的含义。</li>
</ol>
<h4 id="q4：Embedding检索存在哪些限制"><a href="#q4：Embedding检索存在哪些限制" class="headerlink" title="q4：Embedding检索存在哪些限制?"></a><strong>q4：Embedding检索存在哪些限制?</strong></h4><ol>
<li><strong>输入词数限制</strong>： 即便借助Embedding技术选取与查询最为匹配的文本片段供大型模型参考，词汇数量的约束依然存在。当检索覆盖的文本范围广泛时，为了控制注入模型的上下文词汇量，通常会对检索结果设定TopK的阈值K，但这不可避免地引发了信息遗漏的问题。</li>
<li><strong>仅支持文本数据</strong>： 现阶段的GPT-3.5及诸多大型语言模型尚不具备图像识别功能，然而，在知识检索过程中，许多关键信息往往依赖于图文结合来充分理解。例如，学术论文中的示意图、财务报告中的数据图表，仅凭文本难以精准把握其内涵。</li>
<li><strong>大模型的胡编乱造</strong>： 当检索到的相关文献资料不足以支撑大型模型准确回答问题时，为尽力完成响应，模型可能会出现一定程度的“即兴创作”，即在有限信息基础上进行推测与补充。</li>
</ol>
<h2 id="模块三：大模型微调"><a href="#模块三：大模型微调" class="headerlink" title="模块三：大模型微调"></a><strong>模块三：大模型微调</strong></h2><h3 id="为什么-需要-大模型微调？"><a href="#为什么-需要-大模型微调？" class="headerlink" title="为什么 需要 大模型微调？"></a><strong>为什么 需要 大模型微调？</strong></h3><p>通常，要对大模型进行微调，有以下一些原因：</p>
<ol>
<li>第一个原因是，因为大模型的参数量非常大，<strong>训练成本非常高</strong>，每家公司都去从头训练一个自己的大模型，这个事情的性价比非常低；</li>
<li>第二个原因是，<strong>Prompt Engineering的方式是一种相对来说容易上手的使用大模型的方式，但是它的缺点也非常明显</strong>。因为通常大模型的实现原理，都会对输入序列的长度有限制，Prompt Engineering 的方式会把Prompt搞得很长。</li>
</ol>
<p>越长的Prompt，大模型的推理成本越高，因为推理成本是跟Prompt长度的平方正向相关的。</p>
<p>另外，Prompt太长会因超过限制而被截断，进而导致大模型的输出质量打折口，这也是一个非常严重的问题。</p>
<p>对于个人使用者而言，如果是解决自己日常生活、工作中的一些问题，直接用Prompt Engineering的方式，通常问题不大。</p>
<p>但对于对外提供服务的企业来说，要想在自己的服务中接入大模型的能力，推理成本是不得不要考虑的一个因素，微调相对来说就是一个更优的方案。</p>
<ol>
<li>第三个原因是，Prompt Engineering的效果达不到要求，企业又有比较好的自有数据，能够<strong>通过自有数据，更好的提升大模型在特定领域的能力</strong>。这时候微调就非常适用。</li>
<li>第四个原因是，<strong>要在个性化的服务中使用大模型的能力</strong>，这时候针对每个用户的数据，训练一个轻量级的微调模型，就是一个不错的方案。</li>
<li>第五个原因是，<strong>数据安全的问题</strong>。如果数据是不能传递给第三方大模型服务的，那么搭建自己的大模型就非常必要。通常这些开源的大模型都是需要用自有数据进行微调，才能够满足业务的需求，这时候也需要对大模型进行微调。</li>
</ol>
<hr>

</article>
    
    

</div>
<div class="trm-post-next-prev row">
    <div class="col-lg-12">
        <!-- title -->
        <h5 class="trm-title-with-divider">
            其他文章
            <span data-number="02"></span>
        </h5>
    </div>
    
    
        <div class="col-lg-6">
    <div class="trm-older-publications-card trm-scroll-animation trm-active-el">
        <div class="trm-older-publication">
            
            <a class="trm-op-top trm-anima-link" href="/blog/2024/06/15/%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%B7%BB%E5%8A%A0%E8%B4%AD%E7%89%A9%E8%BD%A6%E5%8A%A8%E7%94%BB/">
                <span class="trm-op-cover">
                    <img alt="cover" class="no-fancybox" src="/blog/img/block.jpg">
                </span>
                <h6 class="trm-op-title">小程序添加购物车动画</h6>
            </a>
            <div class="trm-divider trm-mb-15 trm-mt-20"></div>
            <ul class="trm-card-data trm-label">
                <li>24/06/15</li>
                <li>12:03</li>
                <li>未分类</li>
            </ul>
        </div>
    </div>
</div>
    
</div>

    

    <div id="giscus-wrap" class="trm-card trm-scroll-animation comment-container"></div>
<script data-swup-reload-script>
    function loadGiscus() {
        let nowTheme = document.documentElement.classList.contains('dark') ? 'dark' : 'light'
        const config = {
            src: 'https://giscus.app/client.js',
            "data-repo": '2322222223/blog',
            "data-repo-id": 'R_kgDOMCoZ8w',
            "data-category": 'Announcements',
            "data-category-id": 'DIC_kwDOMCoZ884Cfxl-',
            "data-mapping": 'pathname',
            "data-reactions-enabled": '1',
            "data-emit-metadata": '1',
            "data-theme": nowTheme,
            "data-lang": 'zh-CN',
            crossorigin: "anonymous",
            async: true
        }
        let ele = document.createElement('script')
        for (let key in config) {
            ele.setAttribute(key, config[key])
        }
        document.getElementById('giscus-wrap').insertAdjacentElement('afterbegin', ele)
    }

    function changeGiscusTheme() {
        let theme = document.documentElement.classList.contains('dark') ? 'dark' : 'light'

        function sendMessage(message) {
            const iframe = document.querySelector('iframe.giscus-frame');
            if (!iframe) return;
            iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }

        sendMessage({
            setConfig: {
                theme: theme
            }
        });
    }

    loadGiscus();
</script>



                    <div class="trm-divider footer-divider"></div>

                    <!-- footer -->
                    <footer class="trm-footer-card trm-scroll-animation">

    

    
        <div class="trm-footer-item">
            <span>© 2020- 2024</span>
            <span class="footer-separator"data-separator=" · "></span>
            <span class="trm-accent-color">R.linzhou</span>
        </div>
    

      

     

     
</footer>
                    <!-- footer end -->

                </div>
            </div>
        </div>
    </div>
</div>
            <!-- body end -->

            

            
<div class="trm-fixed-container">
    
    
        <div class="trm-fixed-btn" data-title="阅读模式" onclick="asyncFun.switchReadMode()">
            <i class="iconfont fas fa-book-reader"></i>
        </div>
    
    
        <div class="trm-fixed-btn hidden-md" data-title="单栏和双栏切换" onclick="asyncFun.switchSingleColumn()">
            <i class="iconfont fas fa-arrows-alt-h"></i>
        </div>
    
    <div id="trm-back-top" class="trm-fixed-btn" data-title="回到顶部">
        <i class="iconfont fas fa-arrow-up"></i>
    </div>
</div>
        </div>
      </div>
      <!-- scroll container end -->
  </div>
  <!-- app wrapper end -->

  
  <!-- Plugin -->




    
    
<script src="https://unpkg.com/@fancyapps/ui@4.0/dist/fancybox.umd.js"></script>

    

    
        <script src="/blog/js/plugins/typing.js?v=2.2.2"></script>
    

    

    <!-- 数学公式 -->
    

    <!-- 评论插件 -->
    
        

        
    

		




    <!-- Service Worker -->
    
    <script>
        "serviceWorker" in navigator ?
        navigator.serviceWorker.register('/blog/sw.js').then(function () {
            navigator.serviceWorker.controller ? 
             console.log("Assets cached by the controlling service worker.") :
             console.log("Please reload this page to allow the service worker to handle network operations.")
        }).catch(function (e) {
            console.log("ERROR: " + e)
        }) : console.log("Service workers are not supported in the current browser.")
    </script>

    <!-- baidu push -->
    


<script id="async-script" src="/blog/js/main.js?v=2.2.2"></script>

<!-- CDN -->


    

    

    



</body>

</html>